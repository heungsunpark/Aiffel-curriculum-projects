{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b94273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "488fa7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556b7f77",
   "metadata": {},
   "source": [
    "#### [함수 정의] 학습용 데이터 리사이즈 함수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e4dda44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")\n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \" images resized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181113ea",
   "metadata": {},
   "source": [
    "#### 학습용 데이터 불러와서 리사이즈 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2426c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9ca0fe",
   "metadata": {},
   "source": [
    "[함수 정의] 가위, 바위, 보 데이터를 읽을 수 있는 load_data() 함수  \n",
    "- 이 코드를 활용하면 임의의 사진 데이터에 적용 가능\n",
    "- load_data() 함수는 입력으로 이미지가 있는 폴더 위치 필요. 여기서는 rock_scissor_paper 폴더 위치\n",
    "- 가위바위보의 경우 3개의 클래스 즉, 가위: 0, 바위: 1, 보: 2 로 라벨링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7763bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e325e1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c45065",
   "metadata": {},
   "source": [
    "이미지 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34805c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[100])\n",
    "print('라벨: ', y_train[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b22043b",
   "metadata": {},
   "source": [
    "딥러닝 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "869222a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 128)       18560     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1638912   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 1,659,459\n",
      "Trainable params: 1,659,459\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "\n",
    "n_channel_1=16\n",
    "n_channel_2=128\n",
    "n_dense=512\n",
    "n_train_epoch=8\n",
    "\n",
    "# [16, 128, 512] 8: 59%; \n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ce2de2",
   "metadata": {},
   "source": [
    "딥러닝 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd1f4d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "10/10 [==============================] - 3s 16ms/step - loss: 153.2616 - accuracy: 0.3533\n",
      "Epoch 2/8\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 8.4030 - accuracy: 0.4233\n",
      "Epoch 3/8\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9685 - accuracy: 0.6567\n",
      "Epoch 4/8\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5711 - accuracy: 0.7667\n",
      "Epoch 5/8\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4087 - accuracy: 0.8433\n",
      "Epoch 6/8\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2713 - accuracy: 0.9100\n",
      "Epoch 7/8\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1508 - accuracy: 0.9600\n",
      "Epoch 8/8\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0824 - accuracy: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa2d87cf8e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638dbb4d",
   "metadata": {},
   "source": [
    "얼마나 잘 만들었는지 확인하기 - 테스트 데이터 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b67e7903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "테스트 데이터(x_test)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "# 테스트 데이터 로드 함수\n",
    "def load_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"테스트 데이터(x_test)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff40f73",
   "metadata": {},
   "source": [
    "위에서 훈련시킨 model을 사용하여 test_accuracy를 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c3ff4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 3.1651 - accuracy: 0.3867\n",
      "test_loss: 3.16509747505188 \n",
      "test_accuracy: 0.3866666555404663\n"
     ]
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.evaluate()을 사용해 봅시다.\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a255b58d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
